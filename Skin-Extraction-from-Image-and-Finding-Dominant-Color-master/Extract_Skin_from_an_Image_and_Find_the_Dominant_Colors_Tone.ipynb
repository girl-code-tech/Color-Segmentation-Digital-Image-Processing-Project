{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxymLTBIdt39"
   },
   "source": [
    "# How to extract Skin from and Image and Find the Dominant Colours/Tone\n",
    "\n",
    "This the online notebook containing the explaination of the code for the article found at https://goo.gl/bpkVn3 \n",
    "\n",
    "If you are interested in testing out with code create a copy of this notebook and go to  menu on top \"Runtime -> Run All\" or download the notebook in my github -link here-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_UVMQ6PXD2y"
   },
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NiJ0QKzeRxC"
   },
   "source": [
    "## Section One : Importing Libraries\n",
    "\n",
    " - **numpy ** : OpenCV uses Numpy for numerical operation. Hence Numpy is used to align input with the respective data type\n",
    " \n",
    " - **cv2** : OpenCV used for image processing\n",
    " \n",
    " - **Counter** : Useful for counting labels\n",
    " \n",
    " - **imutils** :  Useful utilities for image processing\n",
    " \n",
    " - **pprin**t :  Library to pretty print data\n",
    " \n",
    " - **matplotlib** :  Normally used as a graph plotting lirbary , but we will use it show inline images since \"cv2.imshow\" doesn't work on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuXA7RfbXOut"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import imutils\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZujqTVQEjxaM"
   },
   "source": [
    "## Section Two.1 : Function to Extract Skin Color\n",
    "\n",
    "The ***extractSkin*** function takes an 8 bit 3 channel image in the BGR colorspace (as mentioned in the article this is how OpenCV reads color images) and returns the extracted image in same colorspace. \n",
    "\n",
    "The function works by using the** HSV colorspace** and uses thresholding (Thresholding is a process of filtering out pixel based on specified thresdhold parameter) to extracts pixel that corresponds to the skin color range,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kGCu9pCXYbN"
   },
   "outputs": [],
   "source": [
    "def extractSkin(image):\n",
    "    # Taking a copy of the image\n",
    "    img =  image.copy()\n",
    "    # Converting from BGR Colours Space to HSV\n",
    "    img =  cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Defining HSV Threadholds\n",
    "    lower_threshold = np.array([0, 48, 80], dtype=np.uint8)\n",
    "    upper_threshold = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    # Single Channel mask,denoting presence of colours in the about threshold\n",
    "    skinMask = cv2.inRange(img,lower_threshold,upper_threshold)\n",
    "\n",
    "    # Cleaning up mask using Gaussian Filter\n",
    "    skinMask = cv2.GaussianBlur(skinMask,(3,3),0)\n",
    "\n",
    "    # Extracting skin from the threshold mask\n",
    "    skin  =  cv2.bitwise_and(img,img,mask=skinMask)\n",
    "\n",
    "    # Return the Skin image\n",
    "    return cv2.cvtColor(skin,cv2.COLOR_HSV2BGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "El9UHDb7mvGR"
   },
   "source": [
    "## Section Two.2 :  Function to remove black pixels from extracted image\n",
    "\n",
    "The ***removeBlack*** function is more sort of the utility function to remove out the black pixel from the skin extracted. Since OpenCV by default doesn't handle transparent images and replaces those with zeros(black in color word).\n",
    "\n",
    "This function is useful when thresholding is used in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueCsY8mECI6Q"
   },
   "outputs": [],
   "source": [
    "def removeBlack(estimator_labels, estimator_cluster):  \n",
    "    # Check for black\n",
    "    hasBlack = False\n",
    "\n",
    "    # Get the total number of occurance for each color\n",
    "    occurance_counter = Counter(estimator_labels)\n",
    "\n",
    "\n",
    "    # Quick lambda function to compare to lists\n",
    "    compare = lambda x, y: Counter(x) == Counter(y)\n",
    "\n",
    "    # Loop through the most common occuring color\n",
    "    for x in occurance_counter.most_common(len(estimator_cluster)):\n",
    "\n",
    "    # Quick List comprehension to convert each of RBG Numbers to int\n",
    "    color = [int(i) for i in estimator_cluster[x[0]].tolist() ]\n",
    "\n",
    "\n",
    "\n",
    "    # Check if the color is [0,0,0] that if it is black \n",
    "    if compare(color , [0,0,0]) == True:\n",
    "        # delete the occurance\n",
    "        del occurance_counter[x[0]]\n",
    "        # remove the cluster \n",
    "        hasBlack = True\n",
    "        estimator_cluster = np.delete(estimator_cluster,x[0],0)\n",
    "        break\n",
    "\n",
    "\n",
    "    return (occurance_counter,estimator_cluster,hasBlack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOMlAU75mtix"
   },
   "source": [
    "## Section Two.3 : Extract Colour Information\n",
    "\n",
    "The ***getColorInfomation*** function does all the heavy lifiting to make sense of prediction that came from the clustering.\n",
    "\n",
    "Taking the prediction labels (***estimator_labels***) and the cluster centroids(***estimator_cluster***) as the input and returns an array of dictionaries of the extracted colours.\n",
    "\n",
    "The function also takes an optional parameter (***hasThresholding***) to indicate whether a mask was used. This passed from the ***extractDominantColor*** function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywktI_ISyoFj"
   },
   "outputs": [],
   "source": [
    "def getColorInformation(estimator_labels, estimator_cluster,hasThresholding=False):\n",
    "    occurance_counter = None\n",
    "\n",
    "  \n",
    "  # Variable to keep count of the occurance of each color predicted\n",
    "  \n",
    "  # Output list variable to return\n",
    "    colorInformation = []\n",
    "  \n",
    "  \n",
    "  #Check for Black\n",
    "    hasBlack =False\n",
    "  \n",
    "  # If a mask has be applied, remove th black\n",
    "    if hasThresholding == True:\n",
    "        (occurance,cluster,black) = removeBlack(estimator_labels,estimator_cluster)\n",
    "        occurance_counter =  occurance\n",
    "        estimator_cluster = cluster\n",
    "        hasBlack = black\n",
    "\n",
    "    else:\n",
    "        occurance_counter = Counter(estimator_labels)\n",
    " \n",
    "  # Get the total sum of all the predicted occurances\n",
    "    totalOccurance = sum(occurance_counter.values()) \n",
    "  \n",
    " \n",
    "  # Loop through all the predicted colors\n",
    "    for x in occurance_counter.most_common(len(estimator_cluster)):\n",
    "    \n",
    "        index = (int(x[0]))\n",
    "\n",
    "        # Quick fix for index out of bound when there is no threshold\n",
    "        index =  (index-1) if ((hasThresholding & hasBlack)& (int(index) !=0)) else index\n",
    "\n",
    "        # Get the color number into a list\n",
    "        color = estimator_cluster[index].tolist()\n",
    "\n",
    "        # Get the percentage of each color\n",
    "        color_percentage= (x[1]/totalOccurance)\n",
    "\n",
    "        #make the dictionay of the information\n",
    "        colorInfo = {\"cluster_index\":index , \"color\": color , \"color_percentage\" : color_percentage }\n",
    "\n",
    "        # Add the dictionary to the list\n",
    "        colorInformation.append(colorInfo)\n",
    "\n",
    "\n",
    "    return colorInformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyaNX8GHBsHN"
   },
   "source": [
    "## Section Two.4 : Putting it All together\n",
    "\n",
    "The ***extractDominantColor*** is the function that call the above function to output the information.\n",
    "\n",
    "The function take an 8 bit 3 channel BGR image as the input , the number of colors to be extracted. This does all the super heavy lifting by sparkling some magic power of machine learning.\n",
    "\n",
    "\n",
    "As mention in the article , An unsupervised clustering algorithm, ***KMeans Clustering*** is used to cluster the pixel data based on their RGB values.\n",
    "\n",
    "\n",
    "The function also takes an optional parameter (***hasThresholding***) to indicate whether a thresholding mask was used. This passed to the ***getColorInformation*** function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwMgm-9k-pq6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extractDominantColor(image,number_of_colors=5,hasThresholding=False):\n",
    "  \n",
    "  # Quick Fix Increase cluster counter to neglect the black(Read Article) \n",
    "    if hasThresholding == True:\n",
    "    number_of_colors +=1\n",
    "  \n",
    "  # Taking Copy of the image\n",
    "    img = image.copy()\n",
    "  \n",
    "  # Convert Image into RGB Colours Space\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  \n",
    "  # Reshape Image\n",
    "    img = img.reshape((img.shape[0]*img.shape[1]) , 3)\n",
    "  \n",
    "  #Initiate KMeans Object\n",
    "    estimator = KMeans(n_clusters=number_of_colors, random_state=0)\n",
    "  \n",
    "  # Fit the image\n",
    "    estimator.fit(img)\n",
    "   \n",
    "  # Get Colour Information\n",
    "    colorInformation = getColorInformation(estimator.labels_,estimator.cluster_centers_,hasThresholding)\n",
    "    return colorInformation\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMgmvD0GI1Uh"
   },
   "source": [
    "## Section Two.4.1 : Putting it All together: Making a Visually Representation\n",
    "\n",
    "The ***plotColorBar*** function gives a visually representation of the extracted color information. \n",
    "\n",
    "Taking the color information (***colorInformation***) as input  and returns\n",
    " ***500x100 8 bit 3 channel BGR colorspace image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZtHRM0qn-SH"
   },
   "outputs": [],
   "source": [
    "def plotColorBar(colorInformation):\n",
    "    #Create a 500x100 black image\n",
    "    color_bar = np.zeros((100,500,3), dtype=\"uint8\")\n",
    "  \n",
    "    top_x = 0\n",
    "    for x in colorInformation:    \n",
    "        bottom_x = top_x + (x[\"color_percentage\"] * color_bar.shape[1])\n",
    "\n",
    "        color = tuple(map(int,(x['color'])))\n",
    "  \n",
    "        cv2.rectangle(color_bar , (int(top_x),0) , (int(bottom_x),color_bar.shape[0]) ,color , -1)\n",
    "        top_x = bottom_x\n",
    "    return color_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3xdAIqTOwuU"
   },
   "source": [
    "## Section Two.4.2 : Putting it All together: Pretty Print\n",
    "\n",
    "The function makes print out the color information in a readable manner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV3vAwHG-B8l"
   },
   "outputs": [],
   "source": [
    "def prety_print_data(color_info):\n",
    "    for x in color_info:\n",
    "        print(pprint.pformat(x))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uHKuSb2PM7V"
   },
   "source": [
    "## Section Three: Baking the Pie\n",
    "The below lines of code, is the implementation of the above defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1175
    },
    "colab_type": "code",
    "id": "U7d_APvx9n4Z",
    "outputId": "2648c476-c9d7-4dbc-d104-d02baabc5878"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Skin Image Primary : https://raw.githubusercontent.com/octalpixel/Skin-Extraction-from-Image-and-Finding-Dominant-Color/master/82764696-open-palm-hand-gesture-of-male-hand_image_from_123rf.com.jpg\n",
    "Skin Image One     : https://raw.githubusercontent.com/octalpixel/Skin-Extraction-from-Image-and-Finding-Dominant-Color/master/skin.jpg\n",
    "Skin Image Two     : https://raw.githubusercontent.com/octalpixel/Skin-Extraction-from-Image-and-Finding-Dominant-Color/master/skin_2.jpg\n",
    "Skin Image Three   : https://raw.githubusercontent.com/octalpixel/Skin-Extraction-from-Image-and-Finding-Dominant-Color/master/Human-Hands-Front-Back-Image-From-Wikipedia.jpg\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Get Image from URL. If you want to upload an image file and use that comment the below code and replace with  image=cv2.imread(\"FILE_NAME\")\n",
    "image =  imutils.url_to_image(\"https://raw.githubusercontent.com/octalpixel/Skin-Extraction-from-Image-and-Finding-Dominant-Color/master/82764696-open-palm-hand-gesture-of-male-hand_image_from_123rf.com.jpg\")\n",
    "\n",
    "# Resize image to a width of 250\n",
    "image = imutils.resize(image,width=250)\n",
    "\n",
    "#Show image\n",
    "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Apply Skin Mask\n",
    "skin = extractSkin(image)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(skin,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Find the dominant color. Default is 1 , pass the parameter 'number_of_colors=N' where N is the specified number of colors \n",
    "dominantColors = extractDominantColor(skin,hasThresholding=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Show in the dominant color information\n",
    "print(\"Color Information\")\n",
    "prety_print_data(dominantColors)\n",
    "\n",
    "\n",
    "#Show in the dominant color as bar\n",
    "print(\"Color Bar\")\n",
    "colour_bar = plotColorBar(dominantColors)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(colour_bar)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8sQ_dXQ9-L7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Resize image to a width of 250\n",
    "    image = imutils.resize(frame,width=250)\n",
    "\n",
    "    #Show image\n",
    "    cv2.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "\n",
    "    # Apply Skin Mask\n",
    "    skin = extractSkin(image)\n",
    "\n",
    "    cv2.imshow(cv2.cvtColor(skin,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Find the dominant color. Default is 1 , pass the parameter 'number_of_colors=N' where N is the specified number of colors \n",
    "    dominantColors = extractDominantColor(skin,hasThresholding=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Show in the dominant color information\n",
    "    '''print(\"Color Information\")\n",
    "    prety_print_data(dominantColors)\n",
    "\n",
    "\n",
    "    #Show in the dominant color as bar\n",
    "    print(\"Color Bar\")\n",
    "    colour_bar = plotColorBar(dominantColors)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(colour_bar)\n",
    "    plt.show()'''\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "'''## Gen lower mask (0-5) and upper mask (175-180) of RED\n",
    "mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n",
    "mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))\n",
    "\n",
    "## Merge the mask and crop the red regions\n",
    "mask = cv2.bitwise_or(mask1, mask2 )'''\n",
    "   \n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract Skin from an Image and Find the Dominant Colors/Tone",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
